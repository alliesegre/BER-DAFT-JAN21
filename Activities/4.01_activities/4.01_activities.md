4.01_solution_activity_1.md
Drop: Data can't be obtained, not a lot of entries (rows) or a lot of NaN s in the columns (columns)
Replace: We have some other information that tells us we can do this, even if it is not the missing information. For example, if the data follow an approximately normal distribution, we might want to substitute the missing values with the mean. You always need to have something that "tells you" that you can replace the data.
gender_is_null = data.GENDER.isnull()
data.drop(gender_is_null.index)
data.HOMEOWNR.fillna('U')

2.09_solution_activity_2.md
query = 'select * from table'
data = pd.read_sql_query(query, engine)
data.head()

2.09_solution_activity_3.md
pd.DataFrame(x_normalized).hist()
categorical.info()

2.09_solution_activity_4.md
confusion_matrix(y_test, predictions,normalize='true')
confusion_matrix(y_test, predictions,normalize='pred')

4.01_solution_activity_2.md
It is a regression task that can be solved with linear regression, for example.
from sklearn.linear_model import LinearRegression

X = data[~data.INCOME.isnull()][['HV1', 'IC1']]
y = data[~data.INCOME.isnull()]['INCOME']

X_nulls = data[data.INCOME.isnull()][['HV1', 'IC1']]

model = LinearRegression().fit(X,y)
income_pred = model.predict(X_nulls)
income_pred = np.round(income_pred)
print("Length of predictions: ",len(income_pred))

locations = list(data[data['INCOME'].isnull() == True].index)
print("Length of locations: ",len(locations))

list(data.columns)
col = list(data.columns).index('INCOME')

data.loc[data.INCOME.isnull(),'INCOME'] = income_pred

data.head()


4.01_solution_activity_3.md
A logarithmic scale is common to visualize exponential data as they are the inverse function of each other, so the result would be a linear visualization. This is needed because we visualize exponential functions properly otherwise. As an example, you can see some corona virus visualizations, like this one. Check the log transform with the IC-n columns.

sns.distplot(data['IC1'])
sns.distplot(np.log(data['IC1']))

sns.distplot(data['IC2'])
sns.distplot(np.log(data['IC2']))

sns.distplot(data['IC3'])
sns.distplot(np.log(data['IC3']))

sns.distplot(data['IC4'])
sns.distplot(np.log(data['IC4']))

4.01_solution_activity_4.md
They are completely different:

Map applies a function to all the items in a given list.
Filter creates a list of elements from another for which a function returns true.
Reduce performs some computation on a list and returns the of that computation applied all over the list.
from functools import reduce

lst = list(range(100))
reduce(lambda a,b: a+b, map( np.sqrt, filter(lambda x: x % 2 == 1, lst)), 0)